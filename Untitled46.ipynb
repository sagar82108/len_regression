{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d692b-16bc-4185-b4d2-dc2797045bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "**Simple Linear Regression**:\n",
    "- Uses one independent variable to predict a dependent variable.\n",
    "- Model equation: a0 + a1x \n",
    "- Example: Predicting final exam scores based on hours studied.\n",
    "\n",
    "**Multiple Linear Regression**:\n",
    "- Uses two or more independent variables to predict a dependent variable.\n",
    "- Model equation: a0 + a1x1 + a2x2 + .....\n",
    "- Example: Predicting house sale prices based on bedrooms, square footage, and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda129a4-e439-4a19-b37a-f43f02d1faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    " The key assumptions of linear regression and how to check them briefly:\n",
    "\n",
    "1. **Linearity**: Ensure that the relationship between variables appears linear when plotted.\n",
    "2. **Independence of Errors**: Verify that residuals don't show patterns or trends over time or observations.\n",
    "3. **Homoscedasticity**: Check that the spread of residuals remains fairly consistent across predicted values.\n",
    "4. **Normality of Residuals**: Assess if residuals follow a roughly normal distribution.\n",
    "5. **No or Little Multicollinearity**: Examine correlations or VIF values to ensure minimal multicollinearity.\n",
    "6. **No Perfect Linearity**: Avoid situations where one variable can be perfectly predicted from another.\n",
    "7. **No Outliers**: Identify and handle outliers that can affect the model's accuracy.\n",
    "\n",
    "To check these assumptions, use diagnostic plots, statistical tests, and correlation measures. Adapt the model or interpretation as needed if assumptions are violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b78841-1707-4a4b-9e08-3d622fe3a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a linear regression model:\n",
    "\n",
    "- **Intercept : It represents the predicted value of the dependent variable when all independent variables are zero.\n",
    "          It's the starting point of the regression line but may not always have a meaningful real-world interpretation.\n",
    "\n",
    "- **Slope: It quantifies the change in the dependent variable for a one-unit change in the independent variable, \n",
    "assuming all other variables remain constant. It indicates the direction and strength of the relationship between the variables.\n",
    "\n",
    "Example: In a salary prediction model based on years of experience, \n",
    "the intercept is the estimated starting salary, and the slope is the\n",
    "salary increase for each additional year of experience, holding other factors constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc4a6e-be7c-4bb0-86d0-351453bf01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient descent is an optimization technique used in machine learning to adjust model parameters iteratively. \n",
    "It minimizes a function, typically a loss function, by following the negative gradient's direction. \n",
    "This process helps train models to make accurate predictions or classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e64e5b-b0f7-4159-9d55-6c0bb2ae28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple linear regression is a statistical model that extends simple linear regression\n",
    "by allowing for the analysis of the relationship between a dependent variable and two or \n",
    "more independent variables. Unlike simple linear regression, which involves just one independent variable,\n",
    "multiple linear regression incorporates multiple predictors, \n",
    "making it suitable for modeling complex, multifactorial relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1558e4c-cebb-4908-b0b6-a93171a67d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multicollinearity in multiple linear regression occurs when independent variables are highly correlated, making it challenging to distinguish their individual effects.\n",
    "Detect it by checking correlation matrices or using the Variance Inflation Factor (VIF). Address it by removing or combining correlated variables, using regularization techniques, \n",
    "or applying dimensionality reduction methods like PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551658d0-5f9b-489e-abe5-a443710428f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial regression extends linear regression by allowing for nonlinear relationships between variables.\n",
    "It includes higher-degree terms in the model to capture curved or nonlinear patterns,\n",
    "making it more flexible but potentially harder to interpret than linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bd4d4-7d21-480d-bd8a-08f3dc431556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
